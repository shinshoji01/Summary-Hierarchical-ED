{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Hierarchical Emotion Distribution (ED) Generation\n",
    "---\n",
    "This notebook provides code to automatically generate the hierarchical emotion distribution (ED) from OpenSMILE's acoustic features. It first extracts the distance of the dataset point the decision boudary for each emotion presence classifier. Then, it normalizes those values within the dataset to [0, 1]. We provide the pretrained SVM (`linearsvm_OpenSMILE.pkl`) and the scaler (`scaler_OpenSMILE.pkl`) in our repository so please download it and put them into `Summary-Hierarchical-ED/implementation/parameters/`. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "from IPython.display import clear_output\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "def GetIntensity(scaler, models, feature):\n",
    "    feature = scaler.transform(feature)\n",
    "    length_array = []\n",
    "    for emotion in emos:\n",
    "        bool_list = np.isnan(feature.astype(float)).sum(axis=1).astype(bool)\n",
    "        feature[bool_list] = 0\n",
    "        array = models[emotion].decision_function(feature)\n",
    "        array[bool_list] = np.nan\n",
    "        length_array += [array]\n",
    "    length_array = np.array(length_array)\n",
    "    return length_array\n",
    "\n",
    "def get_words_indices(word_dir):\n",
    "    words_indices = []\n",
    "    for i, w in enumerate(word_dir):\n",
    "        words_indices += [i]*len(word_dir[w])\n",
    "    words_indices = np.array(words_indices)\n",
    "    return words_indices\n",
    "\n",
    "def get_boollist_fastspeech2(words_dir):\n",
    "    bl = [not(key in sil_phones) for key in [e for wd in words_dir.values() for e in wd]]\n",
    "    bl1 = bl.copy()\n",
    "    for idx in range(1, len(bl1)-1):\n",
    "        if not(bl1[idx]):\n",
    "            if bl1[idx-1]:\n",
    "                bl1[idx] = True\n",
    "    bl2 = bl[::-1].copy()\n",
    "    for idx in range(1, len(bl2)-1):\n",
    "        if not(bl2[idx]):\n",
    "            if bl2[idx-1]:\n",
    "                bl2[idx] = True\n",
    "    newbl = np.array(bl1)*np.array(bl2[::-1])\n",
    "    return newbl\n",
    "\n",
    "def GetMinMax_NoOutliers(outputs):\n",
    "    q1, q3 = np.quantile(outputs, [0.25,0.75])\n",
    "    iqr = q3-q1\n",
    "    bool_list = (q1-1.5*iqr<=outputs)*(q3+1.5*iqr>=outputs)\n",
    "    min_ = outputs[bool_list].min()\n",
    "    max_ = outputs[bool_list].max()\n",
    "    return min_, max_, bool_list\n",
    "\n",
    "def normalize_svm(x, min_, max_):\n",
    "    x[x>0] = x[x>0]/max_\n",
    "    x[x<0] = -x[x<0]/min_\n",
    "    return (x+1)/2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "---\n",
    "# Automatic Extraction of Distance from Decision Boundary\n",
    "---\n",
    "\n",
    "This example demonstrates how to extract the distance from the decision boundary for each emotion classifier, using individual SVM classifiers for each emotion.\n",
    "\n",
    "- **`hed_extractor_path`**:  \n",
    "  A string indicating the path to the pretrained SVM model.\n",
    "\n",
    "- **`scaler_path`**:  \n",
    "  A string that indicates the path to the pretrained scaler.\n",
    "  \n",
    "- **`dataset_dir`**:  \n",
    "  A string that indicates the path to the dataset directory.\n",
    "\n",
    "- **`feature_dir`**:  \n",
    "  A string that specifies the directory where the processed features will be saved. This includes both the OpenSMILE features and the additional features generated later in the process.\n",
    "\n",
    "- **`depth`**:  \n",
    "  An integer that defines the directory depth of each wav file relative to `dataset_dir`. For instance, in ESD, `depth=3` because the file path follows the structure:  \n",
    "  `[speaker]/[emotion]/[data split]/[speaker]_[filename].wav`.\n",
    "\n",
    "- **`wav2gt`**:  \n",
    "  A dictionary that maps each wav file path (key) to its corresponding TextGrid file (value).\n",
    "\n",
    "- **`reset`**:  \n",
    "  A boolean value that indicates whether to reset the feature generation process. If set to `False`, the feature generation will be skipped if the feature path already exists.\n",
    "\n",
    "The code generates one file:\n",
    "\n",
    "- **`feature`** (shape: `(12, phoneme_length)`):  \n",
    "   A matrix where each element represents the distance from the SVM decision boundary. The rows are organized as follows:\n",
    "   - **First four rows:** Phoneme-level distances.\n",
    "   - **Next four rows:** Word-level distances.\n",
    "   - **Last four rows:** Utterance-level distances.\n",
    "   \n",
    "   Within each group of four rows, the rows correspond to the following emotions:\n",
    "   - Row 4n: Angry\n",
    "   - Row 4n+1: Happy\n",
    "   - Row 4n+2: Sad\n",
    "   - Row 4n+3: Surprise\n",
    "\n",
    "   This file is saved in `[feature_dir]/HED/raw/`.\n",
    "  \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################\n",
    "########## Adjustable Parameters ##########\n",
    "###########################################\n",
    "\n",
    "hed_extractor_path = '../parameters/linearsvm_OpenSMILE.pkl'\n",
    "scaler_path = '../parameters/scaler_OpenSMILE.pkl'\n",
    "dataset_dir = \"../Dataset/ESD/\"\n",
    "feature_dir = \"../Features/ESD/\"\n",
    "depth = 3\n",
    "wav2tgt = {path: (\"../Dataset/ESD/textgrid_corpus_directory/\"+\"/\".join(path.split(\"/\")[-(depth+1):])).replace(\".wav\", \".TextGrid\") for path in glob.glob(dataset_dir + \"*/\"*depth + \"*\")}\n",
    "reset = False\n",
    "\n",
    "###########################################\n",
    "###########################################\n",
    "###########################################\n",
    "\n",
    "emos = [\"Angry\", \"Happy\", \"Sad\", \"Surprise\"]\n",
    "emos.sort()\n",
    "models = pickle.load(open(hed_extractor_path, 'rb'))\n",
    "scaler = pickle.load(open(scaler_path, 'rb'))\n",
    "split_list = [\"utt\", \"words\", \"phones\"]\n",
    "sil_phones = [\"sil\", \"sp\", \"spn\"]\n",
    "\n",
    "nonexists = []\n",
    "files = glob.glob(feature_dir+\"opensmile/\"+\"*/\"*depth+\"*.npy\")\n",
    "files.sort()\n",
    "for path in tqdm(files):\n",
    "    dn = \"/\".join(path.split(\"/\")[-(depth+1):-1])+\"/\"\n",
    "    bn = os.path.basename(path)[:-4]\n",
    "    savepath = f\"{feature_dir}HED/raw/{dn}{bn}.npy\"\n",
    "    if not(reset) and os.path.exists(savepath):\n",
    "        continue\n",
    "\n",
    "    features = np.load(path, allow_pickle=True).item()\n",
    "    try:\n",
    "        words_dir = np.load(path.replace(\"opensmile\", \"words_phones_dir\"), allow_pickle=True).item()\n",
    "    except EOFError:\n",
    "        nonexists += [dn+bn]\n",
    "        continue\n",
    "        \n",
    "    bl = get_boollist_fastspeech2(words_dir)\n",
    "    words_indices = get_words_indices(words_dir)[bl]\n",
    "\n",
    "    iw = GetIntensity(scaler, models, features[\"words\"])\n",
    "    ip = GetIntensity(scaler, models, features[\"phones\"][:len(bl)])[:,bl]\n",
    "    iu = GetIntensity(scaler, models, features[\"utterance\"])\n",
    "\n",
    "    iw = iw[:, words_indices]\n",
    "    iu = np.repeat(iu, ip.shape[1], axis=1)\n",
    "\n",
    "    feature = np.concatenate([ip, iw, iu], axis=0)\n",
    "    \n",
    "    os.makedirs(os.path.dirname(savepath), exist_ok=True)\n",
    "    np.save(savepath, feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "---\n",
    "# Automatic Extraction of Hierarchical Emotion Distribution (ED)\n",
    "---\n",
    "\n",
    "This example shows how to extract the hierarchical emotion distribution using a min-max normalization approach. In this process, outliers are removed to ensure a more robust calculation.\n",
    "\n",
    "\n",
    "- **`training_files`**:  \n",
    "  A list of files from the training dataset. These files are used to calculate the minimum and maximum distance values required for normalization.\n",
    "\n",
    "  \n",
    "- **`reset`**:  \n",
    "  A boolean value that indicates whether to reset the feature generation process. If set to `False`, the feature generation will be skipped if the feature path already exists.\n",
    "\n",
    "The code generates one file:\n",
    "\n",
    "- **`feature`** (shape: `(12, phoneme_length)`):  \n",
    "   A matrix where each element represents the intensity of an emotion for a specific phoneme. The rows are organized into three levels:\n",
    "   - **First four rows:** Phoneme-level distances.\n",
    "   - **Next four rows:** Word-level distances.\n",
    "   - **Last four rows:** Utterance-level distances.\n",
    "   \n",
    "   Within each group of four rows, the rows correspond to the following emotions:\n",
    "   - Row 4n: Angry\n",
    "   - Row 4n+1: Happy\n",
    "   - Row 4n+2: Sad\n",
    "   - Row 4n+3: Surprise\n",
    "\n",
    "   This file is saved in `[feature_dir]/HED/raw/`.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################\n",
    "########## Adjustable Parameters ##########\n",
    "###########################################\n",
    "\n",
    "training_files = glob.glob(feature_dir+\"HED/raw/*/*/train/*\")\n",
    "reset = True\n",
    "\n",
    "###########################################\n",
    "###########################################\n",
    "###########################################\n",
    "\n",
    "print(\"####################################\")\n",
    "print(\"Compute Min and Max of Training Data\")\n",
    "print(\"####################################\")\n",
    "print()\n",
    "\n",
    "training_files.sort()\n",
    "\n",
    "arrays = []\n",
    "for path in tqdm(training_files):\n",
    "    feature = np.load(path)\n",
    "    arrays += [feature[8:12,0]]\n",
    "    \n",
    "print()\n",
    "min_list = []\n",
    "max_list = []\n",
    "for e in range(len(emos)):\n",
    "    bl = (1-np.isnan(np.array(arrays)).mean(axis=1).astype(bool)).astype(bool)\n",
    "    min_, max_, _ = GetMinMax_NoOutliers(np.array(arrays)[bl][:, e])\n",
    "    min_list.append(min_)\n",
    "    max_list.append(max_)\n",
    "    print(f\"Emotion: {emos[e]}\")\n",
    "    print(f\"    Minimum Value: {min_}\")\n",
    "    print(f\"    Maximum Value: {max_}\")\n",
    "    \n",
    "print()\n",
    "print(\"##################################\")\n",
    "print(\"Compute Normalized Hierarchical ED\")\n",
    "print(\"##################################\")\n",
    "print()\n",
    "    \n",
    "files = glob.glob(feature_dir+\"HED/raw/\"+\"*/\"*depth+\"*.npy\")\n",
    "files.sort()\n",
    "for path in tqdm(files):\n",
    "    dn = \"/\".join(path.split(\"/\")[-(depth+1):-1])+\"/\"\n",
    "    bn = os.path.basename(path)[:-4]\n",
    "\n",
    "    savepath = f\"{feature_dir}HED/normalized/{dn}{bn}.npy\"\n",
    "    if not(reset) and os.path.exists(savepath):\n",
    "        continue\n",
    "    try:\n",
    "        a = np.load(path)\n",
    "    except(FileNotFoundError, ValueError) as error:\n",
    "        continue\n",
    "\n",
    "    for s, segment in enumerate([\"phones\", \"words\"]):\n",
    "        for e in range(len(emos)):\n",
    "            b = normalize_svm(a[s*len(emos)+e], min_list[e], max_list[e])\n",
    "            b[b<0] = 0\n",
    "            b[b>1] = 1\n",
    "            ser = pd.Series(b)\n",
    "            ser.interpolate(method=\"linear\", limit_direction=\"both\", inplace=True)\n",
    "            a[s*len(emos)+e] = ser.values\n",
    "\n",
    "    for e in range(len(emos)):\n",
    "        iu = normalize_svm(a[8+e], min_list[e], max_list[e])\n",
    "        iu[iu<0] = 0\n",
    "        iu[iu>1] = 1\n",
    "        a[8+e] = iu\n",
    "\n",
    "    a[np.isnan(a)] = 0 # this happens when all features are nan\n",
    "    os.makedirs(os.path.dirname(savepath), exist_ok=True)\n",
    "    np.save(savepath, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
