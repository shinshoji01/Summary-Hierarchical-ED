{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import opensmile\n",
    "import glob\n",
    "import numpy as np\n",
    "import librosa\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import tgt\n",
    "\n",
    "def get_words_phones_dir(textgrid):\n",
    "    tier_w = textgrid.get_tier_by_name(\"words\")\n",
    "    text_w = [[interval.end_time, interval.text] for interval in tier_w.intervals]\n",
    "    tier_p = textgrid.get_tier_by_name(\"phones\")\n",
    "    text_p = [[interval.end_time, interval.text] for interval in tier_p.intervals]\n",
    "    word_dir = {}\n",
    "    idx = 0\n",
    "    for i, w in enumerate(text_w):\n",
    "        time, word = w\n",
    "        key = f\"{i}-\"+word\n",
    "        word_dir[key] = []\n",
    "        while True:\n",
    "            time_p, word_p = text_p[idx]\n",
    "            word_dir[key] += [word_p]\n",
    "            idx += 1\n",
    "            if time==time_p:\n",
    "                break\n",
    "    return word_dir, text_w, text_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################\n",
    "########## Adjustable Parameters ##########\n",
    "###########################################\n",
    "\n",
    "fs = 16000\n",
    "dataset_dir = \"../Dataset/ESD/\"\n",
    "feature_dir = \"../Features/ESD/\"\n",
    "depth = 3\n",
    "wav2tgt = {path: (\"../Dataset/ESD/textgrid_corpus_directory/\"+\"/\".join(path.split(\"/\")[-(depth+1):])).replace(\".wav\", \".TextGrid\") for path in glob.glob(dataset_dir + \"*/\"*depth + \"*\")}\n",
    "reset = True\n",
    "\n",
    "###########################################\n",
    "###########################################\n",
    "###########################################\n",
    "\n",
    "smile = opensmile.Smile(\n",
    "    feature_set=opensmile.FeatureSet.eGeMAPSv02, \n",
    "    feature_level=opensmile.FeatureLevel.Functionals,\n",
    "    sampling_rate=fs,\n",
    ")\n",
    "\n",
    "notexists = []\n",
    "files = glob.glob(dataset_dir+\"*/\"*depth+\"*.wav\")\n",
    "files.sort()\n",
    "for path in tqdm(files[:1750]):\n",
    "    dn = \"/\".join(files[0].split(\"/\")[-(depth+1):-1])+\"/\"\n",
    "    bn = os.path.basename(path)[:-4]\n",
    "    feature_path = f\"{feature_dir}opensmile/{dn}{bn}.npy\"\n",
    "    worddir_path = f\"{feature_dir}words_phones_dir/{dn}{bn}.npy\"\n",
    "    if not(reset) and os.path.exists(feature_path) and os.path.exists(worddir_path):\n",
    "        continue\n",
    "    tg_path = wav2tgt[path]\n",
    "    try:\n",
    "        textgrid = tgt.read_textgrid(tg_path)\n",
    "    except FileNotFoundError:\n",
    "        notexists += [tg_path]\n",
    "        continue\n",
    "    word_dir, _, _ = get_words_phones_dir(textgrid)\n",
    "    audio, _ = librosa.load(path, sr=None)\n",
    "    if _!=fs:\n",
    "        audio, _ = librosa.load(path, sr=fs)\n",
    "    alignments = {}\n",
    "\n",
    "    for align in [\"utterance\", \"words\", \"phones\"]:\n",
    "        if align==\"utterance\":\n",
    "            tier = textgrid.get_tier_by_name(\"words\")\n",
    "            start = int(tier.intervals[0].start_time*fs)\n",
    "            end = int(tier.intervals[-1].end_time*fs)\n",
    "            segment = audio[start:end]\n",
    "            collections = np.array(smile.process_signal(segment, fs))\n",
    "            alignments[align] = collections\n",
    "        else:\n",
    "            tier = textgrid.get_tier_by_name(align)\n",
    "            collections = []\n",
    "            for interval in tier.intervals:\n",
    "                segmented_x = audio[int(interval.start_time*fs):int(interval.end_time*fs)]\n",
    "                collections.append(np.array(smile.process_signal(segmented_x, fs))[0])\n",
    "            collections = np.array(collections)\n",
    "            alignments[align] = collections\n",
    "\n",
    "    os.makedirs(os.path.dirname(feature_path), exist_ok=True)\n",
    "    os.makedirs(os.path.dirname(worddir_path), exist_ok=True)\n",
    "    np.save(feature_path, alignments)\n",
    "    np.save(worddir_path, word_dir)\n",
    "    \n",
    "print(\"The following files are not processed due to missing files of TextGrid\")\n",
    "print(notexists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "save = True\n",
    "\n",
    "notexists = []\n",
    "files = glob.glob(dataset_dir+\"*/\"*depth+\"*.wav\")\n",
    "files.sort()\n",
    "for path in tqdm(files):\n",
    "    dn = \"/\".join(path.split(\"/\")[-(depth+1):-1])+\"/\"\n",
    "    bn = os.path.basename(path)[:-4]\n",
    "    feature_path = f\"{feature_dir}opensmile/{dn}{bn}.npy\"\n",
    "    worddir_path = f\"{feature_dir}words_phones_dir/{dn}{bn}.npy\"\n",
    "    if not(reset) and os.path.exists(feature_path) and os.path.exists(worddir_path):\n",
    "        continue\n",
    "    tg_path = wav2tgt[path]\n",
    "    try:\n",
    "        textgrid = tgt.read_textgrid(tg_path)\n",
    "    except FileNotFoundError:\n",
    "        notexists += [tg_path]\n",
    "        continue\n",
    "    word_dir, _, _ = get_words_phones_dir(textgrid)\n",
    "    audio, _ = librosa.load(path, sr=None)\n",
    "    if _!=fs:\n",
    "        audio, _ = librosa.load(path, sr=fs)\n",
    "    alignments = {}\n",
    "\n",
    "    for align in [\"utterance\", \"words\", \"phones\"]:\n",
    "        if align==\"utterance\":\n",
    "            tier = textgrid.get_tier_by_name(\"words\")\n",
    "            start = int(tier.intervals[0].start_time*fs)\n",
    "            end = int(tier.intervals[-1].end_time*fs)\n",
    "            segment = audio[start:end]\n",
    "            collections = np.array(smile.process_signal(segment, fs))\n",
    "            alignments[align] = collections\n",
    "        else:\n",
    "            tier = textgrid.get_tier_by_name(align)\n",
    "            collections = []\n",
    "            for interval in tier.intervals:\n",
    "                segmented_x = audio[int(interval.start_time*fs):int(interval.end_time*fs)]\n",
    "                collections.append(np.array(smile.process_signal(segmented_x, fs))[0])\n",
    "            collections = np.array(collections)\n",
    "            alignments[align] = collections\n",
    "\n",
    "    if save:\n",
    "        os.makedirs(os.path.dirname(feature_path), exist_ok=True)\n",
    "        os.makedirs(os.path.dirname(worddir_path), exist_ok=True)\n",
    "        np.save(feature_path, alignments)\n",
    "        np.save(worddir_path, word_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
