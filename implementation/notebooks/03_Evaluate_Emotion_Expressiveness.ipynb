{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Objective Evaluation for Emotion Expressiveness\n",
    "---\n",
    "This notebook provides the code to compute objective metrics for evaluating emotion expressiveness. The evaluation metrics include mel-cepstral distortion (MCD), pitch/energy distortion, and frame disturbance. The main function for this evaluation is `get_evaluation_scores`, which is implemented in the file `Summary-Hierarchical-ED/implementation/sho_util/pyfiles/objective_evaluation.py`.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import scipy.stats as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../sho_util/pyfiles/\")\n",
    "from basic import get_bool_base_on_conditions\n",
    "from objective_evaluation import get_evaluation_scores\n",
    "\n",
    "def init_scores():\n",
    "    indv_scores = {}\n",
    "    for f in features:\n",
    "        indv_scores[f] = []\n",
    "    return indv_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "# Emotion Similarity among Speakers\n",
    "---\n",
    "\n",
    "Here, we computed the emotion similarity among different speakers in ESD for tutorial. You can easily apply this to your own models by modifying `allfiles` and `gtfiles`.\n",
    "\n",
    "- **`sr`**:  \n",
    "  An integer that specifies the sampling rate of the speech.\n",
    "\n",
    "- **`dataset_dir`** (not neccessary):  \n",
    "  A string that indicates the path to the dataset directory.\n",
    "\n",
    "- **`allfiles`**:  \n",
    "  A dictionary mapping each model name (key) to its corresponding list of WAV files.\n",
    "\n",
    "  \n",
    "- **`gtfiles`**:  \n",
    "  A dictionary mapping each WAV file path (key) to its corresponding ground-truth (reference) file.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################\n",
    "########## Adjustable Parameters ##########\n",
    "###########################################\n",
    "\n",
    "sr = 16000\n",
    "dataset_dir = \"../Dataset/ESD/\"\n",
    "allfiles = {\n",
    "    \"0011\": glob.glob(dataset_dir+\"0011/Neutral/evaluation/*.wav\"),\n",
    "    \"0013\": glob.glob(dataset_dir+\"0013/Neutral/evaluation/*.wav\"),\n",
    "    \"0015\": glob.glob(dataset_dir+\"0015/Neutral/evaluation/*.wav\"),\n",
    "    \"0016\": glob.glob(dataset_dir+\"0016/Neutral/evaluation/*.wav\"),\n",
    "}\n",
    "gtfiles = {path: path.replace(f\"/{key}\", \"/0017\") for key in allfiles for path in allfiles[key]}\n",
    "\n",
    "###########################################\n",
    "###########################################\n",
    "###########################################\n",
    "\n",
    "target_columns = {\n",
    "    (\"mcd\", \"score\"): \"Melcepstral Distortion\",\n",
    "    (\"pitch\", \"score\"): \"Pitch Distortion\",\n",
    "    (\"energy\", \"score\"): \"Energy Distortion\",\n",
    "    (\"mcd\", \"fd\"): \"Frame Disturbance\",\n",
    "}\n",
    "feature_types = [\"mcd\", \"pitch\", \"pitch_remove0\", \"energy\"]\n",
    "score_types = [\"distance\", \"score\", \"fd\"]\n",
    "\n",
    "print(\"################################################\")\n",
    "print(\"Get Objective Evaluation Scores of Target Models\")\n",
    "print(\"################################################\")\n",
    "\n",
    "ges = get_evaluation_scores(sr=sr)\n",
    "features = []\n",
    "for ft in feature_types:\n",
    "    for score_type in score_types:\n",
    "        features += [f\"{ft}-{score_type}\"]\n",
    "scores = {}\n",
    "for key in allfiles:\n",
    "    print(key)\n",
    "    files = allfiles[key]\n",
    "    files.sort()\n",
    "    indv_scores = init_scores()\n",
    "    for path in tqdm(files):\n",
    "        gt_path = gtfiles[path]\n",
    "        data = ges.get(gt_path, path, p_logscale=False, e_logscale=False)\n",
    "        for fname in feature_types:\n",
    "            for v in score_types:\n",
    "                indv_scores[f\"{fname}-{v}\"] += [data[fname][v]]\n",
    "    scores[key] = indv_scores\n",
    "\n",
    "print()\n",
    "print(\"##########################################################\")\n",
    "print(\"Post-processing to Obtain Mean and Interval for each Model\")\n",
    "print(\"##########################################################\")\n",
    "    \n",
    "arrays = []\n",
    "for fname in feature_types:\n",
    "    for v in score_types:\n",
    "        array = {name: scores[name][f\"{fname}-{v}\"] for name in scores}\n",
    "        df = pd.DataFrame(array).describe().loc[[\"mean\"]]\n",
    "        df.index = [f\"{fname}-{v}\"]\n",
    "        arrays += [np.array([fname, v, *df.values[0]])]\n",
    "            \n",
    "new_columns = [\"feature\", \"score type\", *list(df.columns)]\n",
    "df_score = pd.DataFrame(np.array(arrays), columns=new_columns)\n",
    "df_score.loc[:,df.columns] = df_score.loc[:,df.columns].astype(\"float\")\n",
    "df = df_score.T.copy()\n",
    "columns = []\n",
    "for i in range(df.shape[1]):\n",
    "    columns += [(df.loc[\"feature\"].values[i], df.loc[\"score type\"].values[i])]\n",
    "df = df.iloc[2:]\n",
    "df.columns = pd.MultiIndex.from_tuples(columns)\n",
    "mcdmeandf = df.loc[:, list(target_columns)]\n",
    "\n",
    "#create 95% confidence interval for population mean weight\n",
    "df_score_ivl = df_score.copy()\n",
    "for name in scores:\n",
    "    for fname in feature_types:\n",
    "        for v in score_types:\n",
    "            values = scores[name][f\"{fname}-{v}\"]\n",
    "            ivl = st.t.interval(confidence=0.95, df=len(values)-1, loc=np.mean(values), scale=st.sem(values)) \n",
    "            # print(\"    \", name, (ivl[1]-ivl[0])/2)\n",
    "            params = {\"feature\":[fname], \"score type\":[v]}\n",
    "            df_score_ivl.loc[get_bool_base_on_conditions(df_score_ivl, params), name] = (ivl[1]-ivl[0])/2\n",
    "df = df_score_ivl.T.copy()\n",
    "columns = []\n",
    "for i in range(df.shape[1]):\n",
    "    columns += [(df.loc[\"feature\"].values[i], df.loc[\"score type\"].values[i])]\n",
    "df = df.iloc[2:]\n",
    "df.columns = pd.MultiIndex.from_tuples(columns)\n",
    "mcdstddf = df.loc[:, list(target_columns)]\n",
    "\n",
    "df = pd.concat([mcdmeandf, mcdstddf], axis=1)\n",
    "newcolumns = pd.MultiIndex.from_tuples([(cl1, cl2) for cl1 in [\"Mean\", \"Interval\"] for cl2 in list(target_columns.values())])\n",
    "df.columns = newcolumns\n",
    "print()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "This shows the expected output of the metric values. In the example below, the speakers are identified by their IDs along with their genders:\n",
    "\n",
    "- `0011`: Male\n",
    "- `0013`: Male\n",
    "- `0015`: Female\n",
    "- `0016`: Female\n",
    "- `0017` (reference speaker): Female\n",
    "\n",
    "The results indicate that the female speakers (`0015` and `0016`) have higher similarity, particularly with respect to pitch.\n",
    "\n",
    "  <img src=\"images/03_expected_output.png\" width=\"1100\">\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
